import streamlit as st
import FinanceDataReader as fdr
import pandas as pd
import datetime
import requests
import json
import time
import urllib.parse
from bs4 import BeautifulSoup
from pykrx import stock
from io import StringIO
import feedparser
import OpenDartReader
import yfinance as yf
import re
import config
import utils

# ==========================================
# 1. ê¸°ë³¸ ë°ì´í„° ìˆ˜ì§‘ (í¬ë¡¤ë§/API)
# ==========================================

@st.cache_data
def get_krx_list_safe():
    try:
        df_kospi = fdr.StockListing('KOSPI')
        df_kosdaq = fdr.StockListing('KOSDAQ')
        list_df = pd.concat([df_kospi, df_kosdaq])
        if 'Code' not in list_df.columns and 'Symbol' in list_df.columns:
            list_df.rename(columns={'Symbol':'Code'}, inplace=True)
        if 'Name' not in list_df.columns:
            list_df.rename(columns={'Name':'Name'}, inplace=True)
        return list_df[['Code', 'Name']]
    except: return pd.DataFrame()

@st.cache_data(ttl=1800)
def get_market_cycle_status(code):
    try:
        kospi = fdr.DataReader('KS11', datetime.datetime.now()-datetime.timedelta(days=400))
        ma120 = kospi['Close'].rolling(120).mean().iloc[-1]
        curr = kospi['Close'].iloc[-1]
        if curr > ma120: return "ğŸ“ˆ ì‹œì¥ ìƒìŠ¹ì„¸ (ê³µê²©ì  ë§¤ìˆ˜ ìœ íš¨)"
        else: return "ğŸ“‰ ì‹œì¥ í•˜ë½ì„¸ (ë³´ìˆ˜ì  ì ‘ê·¼ í•„ìš”)"
    except: return "ì‹œì¥ ë¶„ì„ ì¤‘"

@st.cache_data(ttl=3600)
def get_macro_data():
    results = {}
    tickers = {"KOSPI": "KS11", "KOSDAQ": "KQ11", "S&P500": "US500", "USD/KRW": "USD/KRW", "US_10Y": "US10YT", "WTI": "CL=F", "êµ¬ë¦¬": "HG=F"}
    for name, code in tickers.items():
        try:
            df = fdr.DataReader(code, datetime.datetime.now()-datetime.timedelta(days=14))
            if not df.empty:
                curr = df.iloc[-1]
                results[name] = {"val": curr['Close'], "change": (curr['Close'] - curr['Open']) / curr['Open'] * 100}
            else: results[name] = {"val": 0.0, "change": 0.0}
        except: results[name] = {"val": 0.0, "change": 0.0}
    if all(v['val'] == 0.0 for v in results.values()): return None
    return results

def get_investor_trend_from_naver(code):
    try:
        url = f"https://finance.naver.com/item/frgn.naver?code={code}"
        headers = {'User-Agent': 'Mozilla/5.0'}
        res = requests.get(url, headers=headers)
        try: dfs = pd.read_html(StringIO(res.text), match='ë‚ ì§œ', header=0, encoding='euc-kr')
        except: dfs = pd.read_html(StringIO(res.text), header=0, encoding='euc-kr')
        
        target_df = None
        for df in dfs:
            if 'ê¸°ê´€' in str(df.columns) and 'ì™¸êµ­ì¸' in str(df.columns): target_df = df; break
        if target_df is None and len(dfs) > 1: target_df = dfs[1]
        
        if target_df is not None:
            df = target_df.dropna().copy()
            df.columns = [c[1] if isinstance(c, tuple) else c for c in df.columns]
            df.rename(columns={'ë‚ ì§œ': 'Date'}, inplace=True)
            inst_col = [c for c in df.columns if 'ê¸°ê´€' in str(c)][0]
            frgn_col = [c for c in df.columns if 'ì™¸êµ­ì¸' in str(c)][0]
            df['ê¸°ê´€'] = df[inst_col].astype(str).str.replace(',', '').astype(float)
            df['ì™¸êµ­ì¸'] = df[frgn_col].astype(str).str.replace(',', '').astype(float)
            df['ê°œì¸'] = -(df['ê¸°ê´€'] + df['ì™¸êµ­ì¸'])
            df['Cum_Individual'] = df['ê°œì¸'].cumsum()
            df['Cum_Foreigner'] = df['ì™¸êµ­ì¸'].cumsum()
            df['Cum_Institution'] = df['ê¸°ê´€'].cumsum()
            return df.iloc[:20]
    except: pass
    return pd.DataFrame()

@st.cache_data(ttl=3600)
def get_investor_trend(code):
    try:
        end_d = datetime.datetime.now().strftime("%Y%m%d")
        start_d = (datetime.datetime.now() - datetime.timedelta(days=60)).strftime("%Y%m%d")
        df = stock.get_market_investor_net_purchase_by_date(start_d, end_d, code)
        if not df.empty:
            df['Cum_Individual'] = df['ê°œì¸'].cumsum()
            df['Cum_Foreigner'] = df['ì™¸êµ­ì¸'].cumsum()
            df['Cum_Institution'] = df['ê¸°ê´€í•©ê³„'].cumsum()
            return df
    except: pass
    return get_investor_trend_from_naver(code)

@st.cache_data(ttl=3600)
def get_financial_history(code):
    try:
        url = f"https://finance.naver.com/item/main.naver?code={code}"
        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
        dfs = pd.read_html(StringIO(res.text), encoding='euc-kr')
        for df in dfs:
            if 'ìµœê·¼ ì—°ê°„ ì‹¤ì ' in str(df.columns) or 'ë§¤ì¶œì•¡' in str(df.iloc[:,0].values):
                df = df.set_index(df.columns[0])
                fin_data = []
                cols = df.columns[-5:-1]
                for col in cols:
                    try:
                        col_name = col[1] if isinstance(col, tuple) else col
                        fin_data.append({
                            "Date": str(col_name).strip(),
                            "ë§¤ì¶œì•¡": float(df.loc['ë§¤ì¶œì•¡', col]),
                            "ì˜ì—…ì´ìµ": float(df.loc['ì˜ì—…ì´ìµ', col]),
                            "ë‹¹ê¸°ìˆœì´ìµ": float(df.loc['ë‹¹ê¸°ìˆœì´ìµ', col])
                        })
                    except: continue
                return pd.DataFrame(fin_data)
        return pd.DataFrame()
    except: return pd.DataFrame()

@st.cache_data(ttl=1200)
def get_company_guide_score(code):
    per, pbr, div = 0.0, 0.0, 0.0
    try:
        url = f"https://finance.naver.com/item/main.naver?code={code}"
        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
        soup = BeautifulSoup(res.text, 'html.parser')
        def get_val(id_name):
            tag = soup.select_one(f"#{id_name}")
            if tag: return float(tag.text.replace(',', '').replace('%', '').replace('ë°°', '').strip())
            return 0.0
        per = get_val("_per"); pbr = get_val("_pbr"); div = get_val("_dvr")
    except: pass
    
    pbr_stat = "good" if 0 < pbr < 1.0 else ("neu" if 1.0 <= pbr < 2.5 else "bad")
    pbr_txt = "ì €í‰ê°€(ì¢‹ìŒ)" if 0 < pbr < 1.0 else ("ì ì •" if 1.0 <= pbr < 2.5 else "ê³ í‰ê°€")
    per_stat = "good" if 0 < per < 10 else ("neu" if 10 <= per < 20 else "bad")
    per_txt = "ì‹¤ì ìš°ìˆ˜" if 0 < per < 10 else ("ë³´í†µ" if 10 <= per < 20 else "ê³ í‰ê°€")
    div_stat = "good" if div > 3.0 else "neu"
    div_txt = "ê³ ë°°ë‹¹" if div > 3.0 else "ì¼ë°˜"
    
    score = 20
    if pbr_stat=="good": score+=15
    if per_stat=="good": score+=10
    if div_stat=="good": score+=5
    
    return min(score, 50), "ë¶„ì„ì™„ë£Œ", {"per": {"val": per, "stat": per_stat, "txt": per_txt}, "pbr": {"val": pbr, "stat": pbr_stat, "txt": pbr_txt}, "div": {"val": div, "stat": div_stat, "txt": div_txt}}

@st.cache_data(ttl=3600)
def get_dart_disclosure_summary(code):
    if not config.USER_DART_KEY: return "DART API í‚¤ ë¯¸ì„¤ì •"
    try:
        dart = OpenDartReader(config.USER_DART_KEY)
        end = datetime.datetime.now().strftime("%Y%m%d")
        start = (datetime.datetime.now() - datetime.timedelta(days=90)).strftime("%Y%m%d")
        df = dart.list(code, start=start, end=end)
        if df is None or df.empty: return "ìµœê·¼ 3ê°œì›” ë‚´ íŠ¹ì´ ê³µì‹œ ì—†ìŒ"
        summary = []
        for _, row in df.head(5).iterrows():
            summary.append(f"[{row['rcept_dt']}] {row['report_nm']}")
        return "\n".join(summary)
    except Exception as e: return f"DART ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"

def get_supply_demand(code):
    try:
        end = datetime.datetime.now().strftime("%Y%m%d")
        start = (datetime.datetime.now() - datetime.timedelta(days=7)).strftime("%Y%m%d")
        df = stock.get_market_investor_net_purchase_by_date(start, end, code)
        if df.empty: return {"f":0, "i":0}
        return {"f": int(df['ì™¸êµ­ì¸'].sum()), "i": int(df['ê¸°ê´€í•©ê³„'].sum())}
    except: return {"f":0, "i":0}

# ==========================================
# 2. ë‰´ìŠ¤ ë° AI ë¶„ì„ (ë³µêµ¬ ì™„ë£Œ)
# ==========================================

def get_naver_finance_news(code):
    news_data = []
    try:
        url = f"https://finance.naver.com/item/news_news.naver?code={code}"
        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
        soup = BeautifulSoup(res.text, 'html.parser')
        for t, d in zip(soup.select('.title'), soup.select('.date')):
            news_data.append({
                "title": t.get_text().strip(),
                "link": "https://finance.naver.com" + t.select_one('a')['href'],
                "date": utils.parse_relative_date(d.get_text().strip()).strftime("%Y-%m-%d")
            })
            if len(news_data) >= 5: break
    except: pass
    return news_data

def get_naver_search_news(keyword):
    news_data = []
    try:
        url = f"https://search.naver.com/search.naver?where=news&query={urllib.parse.quote(keyword)}&sort=1"
        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
        soup = BeautifulSoup(res.text, 'html.parser')
        for item in soup.select('div.news_area')[:5]:
            title_tag = item.select_one('.news_tit')
            date_tag = item.select_one('.info_group span.info')
            if title_tag:
                date_str = date_tag.text.strip() if date_tag else ""
                news_data.append({
                    "title": title_tag.get_text().strip(),
                    "link": title_tag['href'],
                    "date": utils.parse_relative_date(date_str).strftime("%Y-%m-%d")
                })
    except: pass
    return news_data

@st.cache_data(ttl=1800)
def get_hankyung_news_rss():
    news = []
    try:
        feed = feedparser.parse("https://rss.hankyung.com/feed/market")
        for entry in feed.entries[:5]: news.append(f"[í•œê²½] {entry.title}")
    except: pass
    return news

@st.cache_data(ttl=1800)
def get_yahoo_global_news():
    news = []
    try:
        t = yf.Ticker("SPY")
        for n in t.news[:3]: news.append(f"[Global] {n['title']}")
    except: pass
    return news

def call_gemini_dynamic(prompt):
    # [ì¤‘ìš”] config.pyì—ì„œ API í‚¤ë¥¼ í™•ì‹¤í•˜ê²Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    api_key = config.USER_GOOGLE_API_KEY
    if not api_key: return None, "NO_KEY"
    
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key={api_key}"
    try:
        res = requests.post(
            url, 
            headers={"Content-Type": "application/json"}, 
            json={"contents": [{"parts": [{"text": prompt}]}], "generationConfig": {"temperature": 0.0}},
            timeout=30
        )
        if res.status_code == 200: return res.json(), None
        elif res.status_code == 429: time.sleep(1); return None, "Rate Limit"
        return None, f"HTTP {res.status_code}"
    except Exception as e: return None, str(e)

@st.cache_data(ttl=600)
def get_news_sentiment_llm(name, stock_context={}):
    news_list = []
    if stock_context.get('code'): news_list.extend(get_naver_finance_news(stock_context['code']))
    news_list.extend(get_naver_search_news(name))
    
    unique_news = []
    seen = set()
    for n in news_list:
        if n['title'] not in seen:
            seen.add(n['title']); unique_news.append(n)
    
    news_titles = [f"- {n['date']} {n['title']}" for n in unique_news[:5]]
    dart = get_dart_disclosure_summary(stock_context.get('code',''))
    macro = "\n".join(get_hankyung_news_rss()[:3] + get_yahoo_global_news()[:2])
    
    if not news_titles and "ê³µì‹œ ì—†ìŒ" in dart:
         return {"score": 0, "headline": "ìµœê·¼ íŠ¹ì´ ë‰´ìŠ¤ ì—†ìŒ", "opinion": "ì¤‘ë¦½", "risk": "", "catalyst": "", "raw_news": unique_news, "method": "none", "dart_text": dart}

    prompt = f"""
    ë‹¹ì‹ ì€ ì£¼ì‹ íˆ¬ì ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ íˆ¬ì ì˜ê²¬ì„ JSON í˜•ì‹ìœ¼ë¡œ ì£¼ì„¸ìš”.
    
    [ì¢…ëª© ì •ë³´]
    ì¢…ëª©ëª…: {name} ({stock_context.get('code','')})
    í˜„ì¬ê°€: {stock_context.get('current_price',0)}ì›
    ì¶”ì„¸: {stock_context.get('trend','ë¶„ì„ì¤‘')}
    ìˆ˜ê¸‰: {stock_context.get('supply','íŠ¹ì´ì‚¬í•­ ì—†ìŒ')}
    
    [ìµœê·¼ ë‰´ìŠ¤]
    {chr(10).join(news_titles)}
    [DART ê³µì‹œ]
    {dart}
    [ì‹œì¥ ë¶„ìœ„ê¸°]
    {macro}
    
    ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ íˆ¬ì ì˜ê²¬ì„ JSONìœ¼ë¡œ ì£¼ì„¸ìš”.
    í˜•ì‹: {{ "score": -10~10, "opinion": "ë§¤ìˆ˜/ë§¤ë„/ê´€ë§", "summary": "í•œì¤„ìš”ì•½", "catalyst": "í•µì‹¬ì¬ë£Œ", "risk": "ë¦¬ìŠ¤í¬" }}
    JSON ì½”ë“œë§Œ ì¶œë ¥í•˜ì„¸ìš”.
    """
    
    res_data, err = call_gemini_dynamic(prompt)
    if res_data:
        try:
            txt = res_data['candidates'][0]['content']['parts'][0]['text']
            txt = txt.replace("```json", "").replace("```", "").strip()
            match = re.search(r'\{.*\}', txt, re.DOTALL)
            js = json.loads(match.group() if match else txt)
            return {"score": js.get('score', 0), "supply_score": js.get('supply_score', 0), "headline": js.get('summary', "ë¶„ì„ ê²°ê³¼ ì—†ìŒ"), "opinion": js.get('opinion', "ì¤‘ë¦½"), "risk": js.get('risk', "íŠ¹ì´ì‚¬í•­ ì—†ìŒ"), "catalyst": js.get('catalyst', ""), "raw_news": unique_news, "method": "ai", "dart_text": dart}
        except: pass
    return {"score": 0, "headline": "AI ë¶„ì„ ì‹¤íŒ¨ (í‚¤ì›Œë“œ ëŒ€ì²´)", "opinion": "ê´€ë§", "risk": "API ì˜¤ë¥˜", "catalyst": "í‚¤ì›Œë“œ", "raw_news": unique_news, "method": "keyword", "dart_text": dart}

def get_ai_recommended_stocks(keyword):
    prompt = f"ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê²€ìƒ‰ì–´ '{keyword}'ì™€ ê´€ë ¨ëœ í•œêµ­ ì£¼ì‹ 5ê°œë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”. JSON í˜•ì‹: [{{'name':'ì‚¼ì„±ì „ì', 'code':'005930', 'relation':'ëŒ€ì¥ì£¼'}}]"
    res, err = call_gemini_dynamic(prompt)
    if res:
        try:
            txt = res['candidates'][0]['content']['parts'][0]['text'].replace("```json", "").replace("```", "").strip()
            return json.loads(txt), "AI ì¶”ì²œ ì™„ë£Œ"
        except: pass
    return [], "AI ì¶”ì²œ ì‹¤íŒ¨"

@st.cache_data(ttl=1800)
def get_naver_theme_stocks(keyword):
    headers = {'User-Agent': 'Mozilla/5.0'}
    try:
        res = requests.get(f"https://finance.naver.com/sise/theme.naver", headers=headers)
        res.encoding = 'EUC-KR'
        soup = BeautifulSoup(res.text, 'html.parser')
        target_link = None
        for t in soup.select('table.type_1 tr td.col_type1 a'):
            if keyword in t.text:
                target_link = "https://finance.naver.com" + t['href']
                break
        
        if target_link:
            res2 = requests.get(target_link, headers=headers)
            res2.encoding = 'EUC-KR'
            soup2 = BeautifulSoup(res2.text, 'html.parser')
            stocks = []
            for row in soup2.select('div.box_type_l table.type_5 tr'):
                a = row.select_one('td.name a')
                if a: stocks.append({"code": a['href'].split('=')[-1], "name": a.text.strip()})
            return stocks, f"'{keyword}' í…Œë§ˆ {len(stocks)}ê°œ ë°œê²¬"
    except: pass
    return [], "í…Œë§ˆ ê²€ìƒ‰ ì‹¤íŒ¨"

# ==========================================
# 3. í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ (ìŠ¤ë‚˜ì´í¼ ìŠ¤ì½”ì–´ & ì „ëµ)
# ==========================================

def calculate_rsi(data, window=14):
    delta = data.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
    rs = gain / loss
    return 100 - (100 / (1 + rs))

def calculate_atr(data, window=14):
    high = data['High']; low = data['Low']; close = data['Close']
    tr = pd.concat([high-low, (high-close.shift(1)).abs(), (low-close.shift(1)).abs()], axis=1).max(axis=1)
    return tr.rolling(window=window).mean()

def backtest_strategy(df):
    try:
        sim = df.copy()
        sim['Signal'] = (sim['Close'] > sim['MA20']) & (sim['RSI'] < 40)
        wins = 0; total = 0
        signals = sim[sim['Signal']].index
        for date in signals:
            try:
                future = sim.loc[date:].iloc[1:11]
                if not future.empty and future['High'].max() >= sim.loc[date, 'Close'] * 1.03: wins += 1
                total += 1
            except: continue
        return int((wins/total)*100) if total > 0 else 0
    except: return 0

def calculate_sniper_score(code):
    try:
        df = fdr.DataReader(code, datetime.datetime.now() - datetime.timedelta(days=365))
        if len(df) < 60: return 0, [], 0, 0, 0, pd.DataFrame(), ""
        
        df['MA5'] = df['Close'].rolling(5).mean()
        df['MA20'] = df['Close'].rolling(20).mean()
        df['MA60'] = df['Close'].rolling(60).mean()
        df['MA120'] = df['Close'].rolling(120).mean()
        df['RSI'] = calculate_rsi(df['Close'])
        df['ATR'] = calculate_atr(df)
        df['MACD'] = df['Close'].ewm(span=12).mean() - df['Close'].ewm(span=26).mean()
        df['MACD_Signal'] = df['MACD'].ewm(span=9).mean()
        df['BB_Upper'] = df['MA20'] + (df['Close'].rolling(20).std() * 2)
        df['BB_Lower'] = df['MA20'] - (df['Close'].rolling(20).std() * 2)

        curr = df.iloc[-1]; prev = df.iloc[-2]
        score = 0; tags = []
        main_reason = "ê´€ë§ í•„ìš”"
        
        vol_ratio = curr['Volume'] / df['Volume'].rolling(20).mean().iloc[-1] if df['Volume'].rolling(20).mean().iloc[-1] > 0 else 0
        price_chg = (curr['Close'] - prev['Close']) / prev['Close'] * 100
        
        if vol_ratio >= 3.0:
            if price_chg > 0: score += 40; tags.append("ğŸ”¥ ê±°ë˜ëŸ‰í­ë°œ(ë§¤ìˆ˜)"); main_reason = "í°ì† ì“¸ì–´ë‹´ëŠ” ì¤‘"
            else: score -= 50; tags.append("ğŸ˜± íˆ¬ë§¤í­íƒ„(ìœ„í—˜)"); main_reason = "ì„¸ë ¥ ì´íƒˆ ê²½ê³ "
        elif vol_ratio >= 1.5: score += 20; tags.append("ğŸ“ˆ ê±°ë˜ëŸ‰ì¦ê°€")
        
        if curr['Close'] > curr['MA20']: score += 20
        if curr['RSI'] < 30: score += 10; tags.append("ğŸ’ ê³¼ë§¤ë„(ê¸°íšŒ)"); main_reason = "ë°”ë‹¥ ì¡ì„ ì°¬ìŠ¤"
        if curr['MACD'] > curr['MACD_Signal']: score += 10; tags.append("ğŸŒŠ ì¶”ì„¸ì „í™˜")
        
        win_rate = backtest_strategy(df)
        if win_rate >= 70: score += 10; tags.append(f"ğŸ‘‘ ìŠ¹ë¥ {win_rate}%")
        
        if score < 60 and main_reason == "ê´€ë§ í•„ìš”": main_reason = "í˜ ëª¨ìœ¼ëŠ” ì¤‘"
        return score, tags, vol_ratio, price_chg, win_rate, df, main_reason
    except: return 0, [], 0, 0, 0, pd.DataFrame(), "ì˜¤ë¥˜"

def run_single_stock_simulation(df):
    try:
        if len(df) < 100: return None
        balance = 1000000; shares = 0; wins = 0; trades = 0
        sim_df = df.copy()
        
        for i in range(len(sim_df)-90, len(sim_df)):
            row = sim_df.iloc[i]
            if shares == 0 and row['RSI'] < 40 and row['Close'] > row['MA20']:
                shares = int(balance / row['Close']); buy_price = row['Close']; balance -= shares * buy_price; trades += 1
            elif shares > 0:
                profit = (row['Close'] - buy_price) / buy_price
                if profit >= 0.05 or profit <= -0.03:
                    balance += shares * row['Close']; shares = 0
                    if profit > 0: wins += 1
        
        final_asset = balance + (shares * sim_df.iloc[-1]['Close'])
        return {"return": (final_asset - 1000000) / 1000000 * 100, "win_rate": (wins / trades * 100) if trades > 0 else 0, "trades": trades}
    except: return None

def scan_market_candidates(target_df, progress_bar, status_text):
    candidates = []
    limit = min(len(target_df), 50)
    for i in range(limit):
        try:
            row = target_df.iloc[i]
            progress_bar.progress((i+1)/limit)
            status_text.text(f"ìŠ¤ìº” ì¤‘: {row['Name']}")
            df = fdr.DataReader(row['Code'], datetime.datetime.now() - datetime.timedelta(days=100))
            if len(df) < 60: continue
            rsi = calculate_rsi(df['Close']).iloc[-1]
            ma20 = df['Close'].rolling(20).mean().iloc[-1]
            if rsi < 45 and df['Close'].iloc[-1] > ma20:
                candidates.append({"name": row['Name'], "code": row['Code'], "price": df['Close'].iloc[-1], "rsi": round(rsi, 1), "score": "ì¡°ê±´ ë§Œì¡±"})
        except: continue
    return candidates

# ==========================================
# 4. ìµœì¢… í†µí•© ë¶„ì„ (Analyze Pro)
# ==========================================

def analyze_pro(code, name_override=None, relation_tag=None, my_buy_price=None):
    score, tags, vol_ratio, chg_rate, win_rate, df, main_reason = calculate_sniper_score(code)
    if df.empty: return None
    curr = df.iloc[-1]
    name = name_override if name_override else code
    
    ma_status = []
    pass_cnt = 0
    for label, col in [('5ì¼', 'MA5'), ('20ì¼', 'MA20'), ('60ì¼', 'MA60')]:
        if curr['Close'] >= curr.get(col, 0): pass_cnt += 1; ma_status.append({"label": label, "ok": True})
        else: ma_status.append({"label": label, "ok": False})
    
    trend_bonus = 20 if pass_cnt >= 3 else (10 if pass_cnt >= 2 else 0)
    trend_txt = "ê°•ë ¥í•œ ìƒìŠ¹ ì¶”ì„¸" if pass_cnt >= 3 else ("ìƒìŠ¹ì„¸ ìœ ì§€" if pass_cnt >= 2 else "ì¡°ì •/í•˜ë½ì„¸")
    
    fund_score, _, fund_data = get_company_guide_score(code)
    cycle_txt = get_market_cycle_status(code)
    cycle_bonus = 10 if "ìƒìŠ¹ì„¸" in cycle_txt else 0
    investor_bonus = 5 if not get_investor_trend(code).empty else 0
    
    final_score = int((score * 0.5) + fund_score + investor_bonus + trend_bonus + cycle_bonus)
    atr = curr.get('ATR', curr['Close']*0.03)
    current_price = int(curr['Close'])
    
    quant_signal = "ì¤‘ë¦½"
    if my_buy_price:
        profit_rate = (current_price - my_buy_price) / my_buy_price * 100
        action_txt = "ë³´ìœ "
        buy_price = my_buy_price
        target_price = int(buy_price * 1.10)
        stop_price = int(buy_price * 0.95)
        if profit_rate > 10: final_score += 20
        elif profit_rate > 0: final_score += 10
        quant_signal = "ë³´ìœ  ê¶Œì¥" if final_score >= 50 else "ì°¨ìµ/ì†ì ˆ ê³ ë ¤"
    else:
        if final_score >= 80:
            buy_price = current_price
            target_price = int(current_price + (atr * 4))
            stop_price = int(current_price - (atr * 2))
            action_txt = f"ğŸ”¥ ê°•ë ¥ ë§¤ìˆ˜ ({main_reason})"
        elif final_score >= 60:
            buy_price = current_price
            target_price = int(current_price + (atr * 3))
            stop_price = int(current_price - (atr * 1.5))
            action_txt = f"ğŸ“ˆ ë§¤ìˆ˜ ({main_reason})"
        else:
            buy_price = int(curr.get('MA20', current_price*0.95))
            target_price = int(buy_price * 1.10)
            stop_price = int(buy_price * 0.95)
            action_txt = f"ğŸ‘€ ê´€ë§ ({main_reason})"
            
    buy_price = utils.round_to_tick(buy_price)
    target_price = utils.round_to_tick(target_price)
    stop_price = utils.round_to_tick(stop_price)
    
    supply_info = get_supply_demand(code)
    supply_txt = "ì™¸ì¸ë§¤ìˆ˜" if supply_info['f'] > 0 else "íŠ¹ì´ì‚¬í•­ ì—†ìŒ"
    
    context = {"code": code, "trend": trend_txt, "current_price": current_price, "supply": supply_txt, "is_holding": bool(my_buy_price)}
    news_result = get_news_sentiment_llm(name, context)
    
    final_score += news_result.get('score', 0) + news_result.get('supply_score', 0) * 2
    final_score = min(max(final_score, 0), 100)
    
    if my_buy_price: action_txt = news_result.get('opinion', quant_signal)
    
    return {
        "name": name, "code": code, "price": current_price, "change_rate": chg_rate,
        "score": final_score,
        "strategy": {"buy": buy_price, "target": target_price, "stop": stop_price, "action": action_txt, "buy_basis": main_reason},
        "history": df, "relation_tag": relation_tag, "my_buy_price": my_buy_price,
        "stoch": {"k": curr['RSI'], "d": 0}, "vol_ratio": vol_ratio,
        "win_rate": win_rate, "cycle_txt": cycle_txt, "trend_txt": trend_txt,
        "ma_status": ma_status, "fund_data": fund_data,
        "investor_trend": get_investor_trend(code),
        "fin_history": get_financial_history(code),
        "news": news_result
    }
